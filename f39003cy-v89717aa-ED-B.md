---
{}
---
language: en
license: cc-by-4.0
tags:
- text-classification
- evidence-detection
repo: https://github.com/adaim22/NLU-Group40

---

# Model Card for f39003cy-v89717aa-ED-B

<!-- Provide a quick summary of what the model is/does. -->

This model leverages a Bidirectional LSTM to determine the relevance of evidence to claims, focusing on deep learning to capture contextual relationships in text.


## Model Details

### Model Description

<!-- Provide a longer summary of what this model is. -->

The Bidirectional LSTM model processes text sequences to understand and capture the nuances in language that are essential for effective evidence detection. This approach uses deep learning to exploit both past and future context, enhancing prediction accuracy.

- **Developed by:** Bilal Yaqub and AbdelRehman AbdelDaim
- **Language(s):** English
- **Model type:** Supervised
- **Model architecture:** Bidirectional LSTM
- **Finetuned from model [optional]:** Custom Bidirectional LSTM

### Model Resources

<!-- Provide links where applicable. -->

- **Repository:** https://github.com/tensorflow/tensorflow
- **Paper or documentation:** 
      - "Bidirectional LSTM Networks for Improved Phoneme Classification and Recognition" by Schuster and Paliwal, 1997 (https://ieeexplore.ieee.org/document/650093)
      

## Training Details

### Training Data

<!-- This is a short stub of information on the training data that was used, and documentation related to data pre-processing or additional filtering (if applicable). -->

23K claim-evidence pairs from academic and journalistic sources.

### Training Procedure

<!-- This relates heavily to the Technical Specifications. Content here should link to that section when it is relevant to the training procedure. -->

#### Training Hyperparameters

<!-- This is a summary of the values of hyperparameters used in training the model. -->


      - Embedding Layer:
        - Vocabulary size (input_dim): 10000
        - Embedding dimension (output_dim): 100
      - First Bidirectional LSTM Layer:
        - Units per direction: 128
        - Dropout: 0.2
        - Recurrent dropout: 0.2
        - Return sequences: Yes
      - Dropout Layer:
        - Dropout rate: 0.2
      - Second Bidirectional LSTM Layer:
        - Units per direction: 128
        - Dropout: 0.2
        - Recurrent dropout: 0.2
      - Output Layer:
        - Activation function: Sigmoid
      - Compilation:
        - Optimizer: Adam
        - Loss function: Binary crossentropy
        - Evaluation metric: Accuracy
      - Training Process:
        - Number of epochs: 10
        - Batch size: 64
    

#### Speeds, Sizes, Times

<!-- This section provides information about how roughly how long it takes to train the model and the size of the resulting model. -->


      - Overall training time: approx. 182 minutes and 4.3 seconds
      - Duration per training epoch: 1049s
    

## Evaluation

<!-- This section describes the evaluation protocols and provides the results. -->

### Testing Data & Metrics

#### Testing Data

<!-- This should describe any evaluation data used (e.g., the development/validation set provided). -->

Approximately 6K validation pairs.

#### Metrics

<!-- These are the evaluation metrics being used. -->


      - Precision: ~80%
      - Recall: ~81%
      - F1-score: ~79%
      - Accuracy: ~80%

### Results

The model achieved an F1-score of 79% and an accuracy of 80%.

## Technical Specifications

### Hardware


      - RAM: at least 16 GB
      - GPU: Recommended (e.g., Nvidia V100)
      - Storage: at least 4GB

### Software


      - Python 3.8+
      - TensorFlow 2.4+

## Bias, Risks, and Limitations

<!-- This section is meant to convey both technical and sociotechnical limitations. -->

The model may exhibit bias if the training data is not representative of the real-world scenarios it is applied to. The complexity of the LSTM network may lead to overfitting.

## Additional Information

<!-- Any other information that would be useful for other people to know. -->

The choice of hyperparameters was optimized to balance between learning capabilities and computational efficiency.
The trained model is saved here: https://drive.google.com/drive/folders/1G9cDLSvNKo_a2TohnK9imuL_6aFgdhph?usp=sharing
