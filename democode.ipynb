{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the demo code for Group 40\n",
    "\n",
    "All you need to edit are the paths in Cell code 1 (and possibly uncomment the pip install line to install the packages)\n",
    "- Cell code 2 runs category A. Which is a Linear Regression model\n",
    "- Cell code 3 runs category B. Which is a Bidirectional LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-24 12:14:34.487036: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "[nltk_data] Downloading package stopwords to /Users/daim/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import joblib\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# IMPORTANT: If you need to download the packages, please uncomment the below line before running\n",
    "# %pip3 install pandas scikit-learn nltk tensorflow keras\n",
    "\n",
    "# IMPORTANT: THIS IS THE ONLY THING YOU NEED TO UPDATE IN THE CODE\n",
    "input_file_path = 'dev.csv'  # Path to the data file needed\n",
    "\n",
    "lstm_model_path = 'lstm_model.h5'               # Path to the saved LSTM model file\n",
    "output_file_path = 'Group_40_b.csv'  # Path to save the LSTM predictions file\n",
    "tokenizer = joblib.load('lstm_tokenizer.pkl') # Path to the LSTM tokenizer used to train the LSTM model\n",
    "\n",
    "lr_model_path = 'lr_model.pkl'               # Path to the saved LR model file\n",
    "output_file_path_lr = 'Group_40_a.csv'  # Path to save the LR predictions file\n",
    "vectorizer = joblib.load('tfidf_vectorizer.pkl') # Path to the vectorizer used when training the LR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved successfully to Group_40_a.csv\n"
     ]
    }
   ],
   "source": [
    "# Define a function to load the model\n",
    "def load_lr_model(model_path):\n",
    "    \"\"\"Load the pre-trained model from the specified path using pickle.\"\"\"\n",
    "    with open(model_path, 'rb') as file:\n",
    "        model = pickle.load(file)\n",
    "    return model\n",
    "\n",
    "# Define a function for preprocessing the data (adjust according to your actual preprocessing steps)\n",
    "def preprocess(data):\n",
    "    \"\"\"Preprocess the input data and prepare it for model prediction.\"\"\"\n",
    "    # Example: Convert data types, handle missing values, extract features, etc.\n",
    "    data['Claim'] = data['Claim'].fillna('')\n",
    "    data['Evidence'] = data['Evidence'].fillna('')\n",
    "    processed_text = data['Claim'] + \" \" + data['Evidence']\n",
    "    return processed_text\n",
    "\n",
    "# Define a function to make predictions\n",
    "def make_predictions(model, data):\n",
    "    \"\"\"Use the loaded model to make predictions on the processed data.\"\"\"\n",
    "    predictions = model.predict(data)\n",
    "    return predictions\n",
    "\n",
    "# Main execution function\n",
    "def run_demo(input_file_path, model_path, output_file_path_lr):\n",
    "    \"\"\"Load the test data, preprocess it, load the model, make predictions, print metrics, and save the predictions.\"\"\"\n",
    "    # Load the input data\n",
    "    try:\n",
    "        input_data = pd.read_csv(input_file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading the input file: {e}\")\n",
    "        return\n",
    "\n",
    "    # Preprocess the data\n",
    "    processed_data = preprocess(input_data)\n",
    "    X_dev_tfidf = vectorizer.transform(processed_data)\n",
    "\n",
    "    # Load the model\n",
    "    lr_model = load_lr_model(model_path)\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = make_predictions(lr_model, X_dev_tfidf)\n",
    "\n",
    "    # Save the predictions to a CSV file\n",
    "    predictions_df = pd.DataFrame(predictions, columns=['prediction'])\n",
    "    try:\n",
    "        predictions_df.to_csv(output_file_path_lr, index=False)\n",
    "        print(f\"Predictions saved successfully to {output_file_path_lr}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving the predictions: {e}\")\n",
    "\n",
    "# Run the demo\n",
    "run_demo(input_file_path, lr_model_path, output_file_path_lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186/186 [==============================] - 34s 177ms/step\n",
      "Predictions saved successfully to Group_40_b.csv\n"
     ]
    }
   ],
   "source": [
    "# Define a function to load the model\n",
    "def load_lstm_model(model_path):\n",
    "    \"\"\"Load the pre-trained model from the specified path.\"\"\"\n",
    "    lstm_model = load_model(model_path)\n",
    "    return lstm_model\n",
    "\n",
    "# Define a function for preprocessing the data (adjust according to your actual preprocessing steps)\n",
    "def preprocess(data):\n",
    "    \"\"\"Preprocess the input data and prepare it for model prediction.\"\"\"\n",
    "    # Example: Convert data types, handle missing values, extract features, etc.\n",
    "    data['Claim'] = data['Claim'].fillna('')\n",
    "    data['Evidence'] = data['Evidence'].fillna('')\n",
    "    processed_text = data['Claim'] + \" \" + data['Evidence']\n",
    "    return processed_text\n",
    "\n",
    "# Define a function to make predictions\n",
    "def make_predictions(model, data):\n",
    "    \"\"\"Use the loaded model to make predictions on the processed data.\"\"\"\n",
    "    predictions = model.predict(data)\n",
    "    return predictions\n",
    "\n",
    "# Main execution function\n",
    "def run_demo(input_file_path, model_path, output_file_path):\n",
    "    \"\"\"Load the test data, preprocess it, load the model, make predictions, print metrics, and save the predictions.\"\"\"\n",
    "    # Load the input data\n",
    "    try:\n",
    "        input_data = pd.read_csv(input_file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading the input file: {e}\")\n",
    "        return\n",
    "\n",
    "    # Preprocess the data\n",
    "    processed_data = preprocess(input_data)\n",
    "    x_tok_seq = tokenizer.texts_to_sequences(processed_data)\n",
    "    x_padded = pad_sequences(x_tok_seq, maxlen=307, padding='post')\n",
    "\n",
    "    # Load the model\n",
    "    lstm_model = load_lstm_model(model_path)\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = (lstm_model.predict(x_padded) > 0.5).astype(int)\n",
    "\n",
    "    # Save the predictions to a CSV file\n",
    "    predictions_df = pd.DataFrame(predictions, columns=['prediction'])\n",
    "    try:\n",
    "        predictions_df.to_csv(output_file_path, index=False)\n",
    "        print(f\"Predictions saved successfully to {output_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving the predictions: {e}\")\n",
    "\n",
    "# Run the demo\n",
    "run_demo(input_file_path, lstm_model_path, output_file_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
