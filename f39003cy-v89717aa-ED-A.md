---
{}
---
language: en
license: cc-by-4.0
tags:
- text-classification
- evidence-detection
repo: https://github.com/adaim22/NLU-Group40

---

# Model Card for f39003cy-v89717aa-ED-A

<!-- Provide a quick summary of what the model is/does. -->

This model uses Linear Regression with TF-IDF vectorization to determine the relevance of evidence to claims, emphasizing feature-based statistical learning approaches.


## Model Details

### Model Description

<!-- Provide a longer summary of what this model is. -->

The model employs Linear Regression with TF-IDF vectorization to analyze text data, capturing keyword importance and correlations for evidence detection. This approach is grounded in traditional statistical learning, making it robust for sparse data scenarios.

- **Developed by:** Bilal Yaqub and Abdelrehman Abdeldaim
- **Language(s):** English
- **Model type:** Supervised
- **Model architecture:** Linear Regression with TF-IDF
- **Finetuned from model [optional]:** Standard Linear Regression with TF-IDF

### Model Resources

<!-- Provide links where applicable. -->

- **Repository:** NA
- **Paper or documentation:** NA

## Training Details

### Training Data

<!-- This is a short stub of information on the training data that was used, and documentation related to data pre-processing or additional filtering (if applicable). -->

23K claim-evidence pairs from academic and journalistic sources.

### Training Procedure

<!-- This relates heavily to the Technical Specifications. Content here should link to that section when it is relevant to the training procedure. -->

#### Training Hyperparameters

<!-- This is a summary of the values of hyperparameters used in training the model. -->


      - max_features: 10000
      - stop_words: english
      

#### Speeds, Sizes, Times

<!-- This section provides information about how roughly how long it takes to train the model and the size of the resulting model. -->


      - Overall training time: approx. 0.4 seconds
      

## Evaluation

<!-- This section describes the evaluation protocols and provides the results. -->

### Testing Data & Metrics

#### Testing Data

<!-- This should describe any evaluation data used (e.g., the development/validation set provided). -->

Approximately 6K validation pairs.

#### Metrics

<!-- These are the evaluation metrics being used. -->


      - Precision: ~80%
      - Recall: ~81%
      - F1-score: ~79%
      - Accuracy: ~80%

### Results

The model achieved an F1-score of 79% and an accuracy of 80%.

## Technical Specifications

### Hardware


      - RAM: at least 8 GB
      - Storage: at least 1GB

### Software


      - Python 3.8+
      - Scikit-Learn 0.24+

## Bias, Risks, and Limitations

<!-- This section is meant to convey both technical and sociotechnical limitations. -->

The model may exhibit bias if the training data is not representative of the real-world scenarios it is applied to. Overfitting is another risk due to the simplicity of the model.

## Additional Information

<!-- Any other information that would be useful for other people to know. -->

The choice of hyperparameters was based on preliminary experiments that suggested a balance between simplicity and performance.
